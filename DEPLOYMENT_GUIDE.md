# üöÄ Guide de D√©ploiement Complet - Chatbot UM5

## üìã Table des Mati√®res

1. [Export depuis Kaggle](#1-export-depuis-kaggle)
2. [Configuration Locale](#2-configuration-locale)
3. [D√©ploiement Local](#3-d√©ploiement-local)
4. [D√©ploiement Cloud](#4-d√©ploiement-cloud)
5. [Partage du Lien](#5-partage-du-lien)

---

## 1Ô∏è‚É£ Export depuis Kaggle

### √âtape 1.1 : Ajouter le script d'export √† votre notebook

√Ä la **fin de votre notebook Kaggle**, ajoutez cette cellule :

```python
# ============================================================================
# EXPORT DES MOD√àLES POUR D√âPLOIEMENT
# ============================================================================

import os
import shutil

KAGGLE_OUTPUT = '/kaggle/working'
EXPORT_DIR = f'{KAGGLE_OUTPUT}/deployment_package'
os.makedirs(EXPORT_DIR, exist_ok=True)

# Cr√©er structure
os.makedirs(f'{EXPORT_DIR}/models', exist_ok=True)
os.makedirs(f'{EXPORT_DIR}/data', exist_ok=True)

# Copier mod√®le Intent
shutil.copytree(
    f'{KAGGLE_OUTPUT}/um5_hybrid_model',
    f'{EXPORT_DIR}/models/um5_hybrid_model'
)

# Copier donn√©es RAG
shutil.copy2(f'{KAGGLE_OUTPUT}/vector_database.npz', f'{EXPORT_DIR}/data/')
shutil.copy2(f'{KAGGLE_OUTPUT}/knowledge_base.json', f'{EXPORT_DIR}/data/')

# Cr√©er archive
shutil.make_archive(
    f'{KAGGLE_OUTPUT}/um5_deployment',
    'zip',
    EXPORT_DIR
)

print("‚úÖ Package cr√©√© : um5_deployment.zip")
print(f"üì• T√©l√©chargez-le depuis l'onglet Output de Kaggle")
```

### √âtape 1.2 : T√©l√©charger le package

1. Ex√©cuter la cellule
2. Aller dans **Output** ‚Üí **Data**
3. T√©l√©charger `um5_deployment.zip` (~500MB)

---

## 2Ô∏è‚É£ Configuration Locale

### √âtape 2.1 : Pr√©parer votre environnement

```bash
# Cr√©er dossier projet
mkdir um5-chatbot-demo
cd um5-chatbot-demo

# Extraire le package Kaggle
unzip um5_deployment.zip

# Structure attendue :
# um5-chatbot-demo/
# ‚îú‚îÄ‚îÄ models/
# ‚îÇ   ‚îî‚îÄ‚îÄ um5_hybrid_model/
# ‚îú‚îÄ‚îÄ data/
# ‚îÇ   ‚îú‚îÄ‚îÄ vector_database.npz
# ‚îÇ   ‚îî‚îÄ‚îÄ knowledge_base.json
```

### √âtape 2.2 : T√©l√©charger les fichiers de l'app

T√©l√©chargez depuis mon repo (ou cr√©ez localement) :

- `app.py` - Application FastAPI
- `requirements.txt` - D√©pendances Python
- `static/index.html` - Interface web
- `Dockerfile` - Configuration Docker (optionnel)

### √âtape 2.3 : Installer les d√©pendances

```bash
# Cr√©er environnement virtuel (recommand√©)
python -m venv venv

# Activer
# Windows :
venv\Scripts\activate
# Linux/Mac :
source venv/bin/activate

# Installer d√©pendances
pip install -r requirements.txt
```

---

## 3Ô∏è‚É£ D√©ploiement Local

### Option A : Ex√©cution Directe (D√©veloppement)

```bash
# Lancer le serveur
python app.py

# Ou avec uvicorn directement
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

**Acc√®s :**
- Interface web : http://localhost:8000
- API Documentation : http://localhost:8000/docs
- Health check : http://localhost:8000/health

### Option B : Docker (Production)

```bash
# Build l'image
docker build -t um5-chatbot .

# Lancer le container
docker run -d -p 8000:8000 --name um5-chatbot um5-chatbot

# V√©rifier les logs
docker logs -f um5-chatbot

# Arr√™ter
docker stop um5-chatbot
```

---

## 4Ô∏è‚É£ D√©ploiement Cloud

### Option 1 : Hugging Face Spaces (GRATUIT, RECOMMAND√â) üåü

**Avantages** :
- ‚úÖ Gratuit pour projets publics
- ‚úÖ GPU gratuit disponible
- ‚úÖ URL publique automatique
- ‚úÖ Tr√®s facile

**√âtapes** :

1. **Cr√©er un compte** : https://huggingface.co/join

2. **Cr√©er un nouveau Space** :
   - Aller sur https://huggingface.co/new-space
   - Nom : `um5-chatbot-demo`
   - SDK : **Gradio** ou **Docker**
   - Licence : MIT
   - Visibilit√© : Public

3. **Upload les fichiers** :

```bash
# Cloner le repo du Space
git clone https://huggingface.co/spaces/VOTRE_USERNAME/um5-chatbot-demo
cd um5-chatbot-demo

# Copier vos fichiers
cp -r ../um5-chatbot-demo/* .

# Commit et push
git add .
git commit -m "Initial deployment"
git push
```

4. **Attendre le build** (~5-10 min)

5. **Votre lien** : `https://huggingface.co/spaces/VOTRE_USERNAME/um5-chatbot-demo`

---

### Option 2 : Render (GRATUIT avec limitations)

**Avantages** :
- ‚úÖ Gratuit (plan Starter)
- ‚úÖ Facile √† configurer
- ‚úÖ Auto-deploy depuis GitHub

**√âtapes** :

1. **Cr√©er compte** : https://render.com

2. **Pr√©parer repo GitHub** :
```bash
# Cr√©er repo GitHub et push votre code
git init
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/VOTRE_USERNAME/um5-chatbot.git
git push -u origin main
```

3. **Sur Render.com** :
   - New ‚Üí Web Service
   - Connect GitHub repo
   - Configuration :
     - Name : `um5-chatbot`
     - Environment : Python 3
     - Build Command : `pip install -r requirements.txt`
     - Start Command : `uvicorn app:app --host 0.0.0.0 --port $PORT`
   - Click "Create Web Service"

4. **Votre lien** : `https://um5-chatbot.onrender.com`

**‚ö†Ô∏è Limitations du plan gratuit** :
- Se met en veille apr√®s 15 min d'inactivit√©
- Red√©marre √† la prochaine visite (~30s)
- 750h/mois de runtime

---

### Option 3 : Railway (GRATUIT avec limitations)

**Avantages** :
- ‚úÖ $5 de cr√©dits gratuits/mois
- ‚úÖ Tr√®s simple
- ‚úÖ Bonne performance

**√âtapes** :

1. **Cr√©er compte** : https://railway.app

2. **New Project** ‚Üí Deploy from GitHub

3. **Variables d'environnement** (Settings) :
```
PORT=8000
PYTHONUNBUFFERED=1
```

4. **Votre lien** : `https://VOTRE_APP.up.railway.app`

---

### Option 4 : Google Cloud Run (Payant mais gratuit jusqu'√† 2M requ√™tes/mois)

**Avantages** :
- ‚úÖ Tr√®s scalable
- ‚úÖ Pay-per-use
- ‚úÖ Tier gratuit g√©n√©reux

**√âtapes** :

```bash
# Installer gcloud CLI
# https://cloud.google.com/sdk/docs/install

# Login
gcloud auth login

# Cr√©er projet
gcloud projects create um5-chatbot --set-as-default

# Enable APIs
gcloud services enable cloudbuild.googleapis.com run.googleapis.com

# Build et deploy
gcloud builds submit --tag gcr.io/um5-chatbot/chatbot
gcloud run deploy um5-chatbot \
  --image gcr.io/um5-chatbot/chatbot \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

**Votre lien** : Affich√© apr√®s le deploy

---

### Option 5 : Azure Web App (Payant, gratuit avec compte √©tudiant)

Si vous avez **Azure for Students** (100$ de cr√©dits gratuits) :

```bash
# Installer Azure CLI
# https://docs.microsoft.com/cli/azure/install-azure-cli

# Login
az login

# Cr√©er resource group
az group create --name um5-chatbot-rg --location westeurope

# Cr√©er App Service plan (F1 = gratuit)
az appservice plan create \
  --name um5-plan \
  --resource-group um5-chatbot-rg \
  --sku F1 \
  --is-linux

# Deploy from Docker
az webapp create \
  --resource-group um5-chatbot-rg \
  --plan um5-plan \
  --name um5-chatbot-demo \
  --deployment-container-image-name VOTRE_DOCKERHUB_IMAGE

# Ou deploy depuis GitHub
az webapp up --name um5-chatbot-demo --location westeurope
```

---

## 5Ô∏è‚É£ Partage du Lien

### üéØ Pour une D√©monstration Professionnelle

1. **Personnaliser le domaine** (optionnel) :
   - Hugging Face : Gratuit, pas de custom domain
   - Render : Custom domain sur plan payant
   - Railway : Custom domain inclus

2. **Cr√©er une page de pr√©sentation** :

```markdown
# üéì Chatbot UM5 - D√©monstration

## üîó Lien de d√©mo : https://VOTRE_LIEN_ICI

## üìä Caract√©ristiques

- **Pr√©cision** : 89.7%
- **Latence** : ~180ms
- **Architecture** : Hybride (Intent + RAG + LLM)
- **Support** : Multilingue (Fr/Ar/En)

## üöÄ Fonctionnalit√©s

1. Classification d'intention (XLM-RoBERTa)
2. Recherche s√©mantique (RAG)
3. Fallback intelligent (LLM)

## üì± Utilisation

1. Ouvrir le lien
2. Poser une question
3. Voir les r√©ponses en temps r√©el avec m√©triques

## üìß Contact

- Email : votre.email@um5.ac.ma
- GitHub : https://github.com/VOTRE_USERNAME/um5-chatbot
```

3. **Partager** :
   - LinkedIn : Post avec screenshot + lien
   - Email prof/jury : Template ci-dessous
   - README GitHub : Ajouter badge de d√©mo

---

## üìß Template Email pour Jury/Prof

```
Objet : D√©monstration - Chatbot Universitaire UM5 (Architecture Hybride)

Bonjour [Nom],

Je vous pr√©sente mon projet de fin d'√©tudes : un chatbot intelligent pour 
l'Universit√© Mohammed V utilisant une architecture hybride innovante.

üîó D√©mo en ligne : https://VOTRE_LIEN

üìä R√©sultats :
- Pr√©cision : 89.7%
- Latence : 180ms
- Architecture : Intent Classification + RAG + LLM Fallback

üìÇ Documentation compl√®te :
- GitHub : https://github.com/VOTRE_USERNAME/um5-chatbot
- Rapport : [lien vers PDF]

La d√©mo est accessible 24/7 et permet de tester l'ensemble des 
fonctionnalit√©s en temps r√©el.

N'h√©sitez pas si vous avez des questions !

Cordialement,
[Votre Nom]
```

---

## üõ†Ô∏è D√©pannage

### Probl√®me : Mod√®le trop gros pour d√©ployer

**Solution** : Utiliser un service avec plus de stockage
- Hugging Face : 50GB gratuit
- Google Cloud Run : Storage illimit√©
- Compresser le mod√®le (quantization)

### Probl√®me : Latence √©lev√©e en production

**Solutions** :
1. Activer GPU (Hugging Face Spaces)
2. Utiliser un CDN pour les assets statiques
3. Impl√©menter du caching Redis
4. Optimiser avec ONNX Runtime

### Probl√®me : Out of Memory

**Solutions** :
1. R√©duire batch_size dans le code
2. Utiliser FP16 (half precision)
3. Upgrader le plan (plus de RAM)

---

## ‚úÖ Checklist de D√©ploiement

- [ ] Mod√®les export√©s depuis Kaggle
- [ ] D√©pendances install√©es localement
- [ ] Test local r√©ussi (http://localhost:8000)
- [ ] Code push√© sur GitHub
- [ ] Service cloud choisi et configur√©
- [ ] D√©ploiement r√©ussi
- [ ] Tests fonctionnels sur le lien public
- [ ] Documentation README.md √† jour
- [ ] Lien partag√© avec jury/prof

---

## üìö Ressources Suppl√©mentaires

- [Documentation FastAPI](https://fastapi.tiangolo.com)
- [Hugging Face Spaces Guide](https://huggingface.co/docs/hub/spaces)
- [Render Deployment Guide](https://render.com/docs)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)

---

**Bonne chance pour votre d√©monstration ! üöÄ**
